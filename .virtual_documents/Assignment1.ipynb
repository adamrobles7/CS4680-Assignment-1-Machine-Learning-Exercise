# ==========================================
# Car Price: Simple Deal Classifier + Minimal ML
# ------------------------------------------
# Purpose:
#   - Load car_sales_data.csv
#   - Create a simple (heuristic) estimated price and prevent negatives
#   - Label each row "Good deal" or "Bad deal" using a $5,000 tolerance
#   - Train TWO scikit-learn models (Linear Regression, Random Forest)
#     and report test-set metrics vs. the naive baseline
#   - Output a table with the requested columns and labels
#
# Assumes the CSV has columns:
#   Manufacturer, Model, Engine size, Fuel type, Year of manufacture, Mileage, Price
# ==========================================

import re
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

pd.set_option("display.max_columns", 200)

# ---- 1) Load data ----
df = pd.read_csv("car_sales_data.csv")

# ---- 2) Clean and prepare columns ----
def to_float(x):
    """
    Convert strings like "$12,345", "2.0L", "150,000 mi" to float.
    Returns np.nan if value cannot be parsed.
    """
    if pd.isna(x):
        return np.nan
    s = re.sub(r"[^0-9.\-]", "", str(x))  # keep digits, decimal point, minus sign
    return float(s) if s not in ("", ".", "-") else np.nan

# Coerce numeric fields to float
num_cols = ["Engine size", "Year of manufacture", "Mileage", "Price"]
for c in num_cols:
    df[c] = df[c].apply(to_float)

# Normalize categorical fields; fill missing with "Unknown"
cat_cols = ["Manufacturer", "Model", "Fuel type"]
for c in cat_cols:
    df[c] = df[c].astype(str).str.strip().replace({"": np.nan})
df[cat_cols] = df[cat_cols].fillna("Unknown")

# Require a real price for each row; median-impute remaining numeric NaNs
df = df.dropna(subset=["Price"]).reset_index(drop=True)
for c in num_cols:
    df[c] = df[c].fillna(df[c].median())

# ---- 3) Estimated price (naive heuristic, NOT learned) ----
# Start at dataset median price; adjust by engine size, year, and mileage vs. their medians.
med_price  = df["Price"].median()
med_engine = df["Engine size"].median()
med_year   = df["Year of manufacture"].median()
med_miles  = df["Mileage"].median()

def naive_price(row):
    base = med_price
    base += 2000 * (row["Engine size"] - med_engine)          # +$2,000 per liter vs median
    base +=  800 * (row["Year of manufacture"] - med_year)    # +$800 per year vs median
    base += -500 * ((row["Mileage"] - med_miles) / 10000.0)   # -$500 per 10k miles vs median
    return base

df["Estimated price"] = df.apply(naive_price, axis=1)
df["Estimated price"] = df["Estimated price"].clip(lower=0)   # no negative estimates

# ---- 4) Good/Bad deal classification with a $5,000 tolerance ----
diff = (df["Price"] - df["Estimated price"]).abs()
df["Good or bad deal"] = np.where(diff > 5000, "Bad deal", "Good deal")

# ---- 5) Minimal ML: train two models and report metrics on a test set ----
# Features for ML and target
feature_cols = ["Manufacturer", "Model", "Engine size", "Fuel type", "Year of manufacture", "Mileage"]
X = df[feature_cols].copy()
y = df["Price"].copy()

# One-hot encode categoricals (simple, no pipelines)
X_enc = pd.get_dummies(X, columns=["Manufacturer", "Model", "Fuel type"], drop_first=True)

# Split; keep indices to fetch the naive baseline for the same test rows
X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(
    X_enc, y, df.index, test_size=0.2, random_state=42
)

# Models
lin = LinearRegression().fit(X_train, y_train)
rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1).fit(X_train, y_train)

# Predictions
pred_lin = lin.predict(X_test)
pred_rf  = rf.predict(X_test)
pred_naive = df.loc[idx_test, "Estimated price"].values  # naive baseline on the same test rows

# Backward-compatible RMSE (works on older scikit-learn w/o squared=False)
def rmse_compat(y_true, y_pred):
    try:
        return mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        return np.sqrt(mean_squared_error(y_true, y_pred))

def report_metrics(name, y_true, y_pred):
    mae  = mean_absolute_error(y_true, y_pred)
    rmse = rmse_compat(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    print(f"{name:14s} | MAE: {mae:,.0f} | RMSE: {rmse:,.0f} | RÂ²: {r2:0.3f}")

print("\n=== Test-set price prediction metrics (lower is better) ===")
report_metrics("Naive baseline", y_test, pred_naive)
report_metrics("LinearReg",      y_test, pred_lin)
report_metrics("RandomForest",   y_test, pred_rf)

# ---- 6) Assemble final output table (as requested) ----
result = df[[
    "Manufacturer",
    "Model",
    "Engine size",
    "Fuel type",
    "Year of manufacture",
    "Mileage"
]].copy()

result["Real price"] = df["Price"]
result["Estimated price"] = df["Estimated price"]
result["Good or bad deal"] = df["Good or bad deal"]

# Optional: save artifacts
# result.to_csv("car_deal_evaluation.csv", index=False)

# Display table in Jupyter
result




